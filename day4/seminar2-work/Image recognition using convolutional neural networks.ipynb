{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar 6\n",
    "# Image recognition using convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.333)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph model\n",
    "\n",
    "Keras allows to build networks of any kind, not just squeantially connected list of layers (a.k.a feed-forward).\n",
    "In order to do this, we need to define network graph first and then create a model:\n",
    "\n",
    "```python\n",
    "\n",
    "input1 = Input(shape=(...))\n",
    "\n",
    "layer = SuperLayer(params)(input1)\n",
    "...\n",
    "\n",
    "network = Model([input1], [output1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an X-shaped network as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_x_net():\n",
    "    ### Input layers serve as starting points in networks. \n",
    "    input1 = Input(shape=(100, ), name='Input_1')\n",
    "    dense1 = Dense(units=100, name='Dense_layer_1')(input1)\n",
    "    \n",
    "    input2 = Input(shape=(100, ), name='Input_2')\n",
    "    dense2 = Dense(units=100, name='Dense_layer_2')(input2)\n",
    "    \n",
    "    shared = Concatenate(name='Shared_features')([dense1, dense2])\n",
    "    \n",
    "    dense3 = Dense(units=100, name='Dense_layer_3')(shared)\n",
    "    concat1 = Concatenate(name='Concatenate_1')([dense1, dense3])\n",
    "    output1 = Dense(units=100, name='Output_1')(concat1)\n",
    "    \n",
    "    dense4 = Dense(units=100, name='Dense_layer_4')(shared)\n",
    "    concat2 = Concatenate(name='Concatenate_2')([dense2, dense4])\n",
    "    output2 = Dense(units=100, name='Output_2')(concat2)\n",
    "    \n",
    "    ### model just needs to know which nodes are inputs\n",
    "    ### and which are outputs\n",
    "    return Model([input1, input2], [output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_shaped_net = make_x_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 411.50 410.00\" width=\"412pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 407.5,-406 407.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4564384464 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4564384464</title>\n",
       "<polygon fill=\"none\" points=\"6.5,-365.5 6.5,-401.5 136.5,-401.5 136.5,-365.5 6.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.5\" y=\"-379.8\">Input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4543028560 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4543028560</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 143,-328.5 143,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.5\" y=\"-306.8\">Dense_layer_1: Dense</text>\n",
       "</g>\n",
       "<!-- 4564384464&#45;&gt;4543028560 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4564384464-&gt;4543028560</title>\n",
       "<path d=\"M71.5,-365.4551C71.5,-357.3828 71.5,-347.6764 71.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"75.0001,-338.5903 71.5,-328.5904 68.0001,-338.5904 75.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4564254288 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4564254288</title>\n",
       "<polygon fill=\"none\" points=\"207.5,-365.5 207.5,-401.5 337.5,-401.5 337.5,-365.5 207.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-379.8\">Input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4799870736 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4799870736</title>\n",
       "<polygon fill=\"none\" points=\"201,-292.5 201,-328.5 344,-328.5 344,-292.5 201,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-306.8\">Dense_layer_2: Dense</text>\n",
       "</g>\n",
       "<!-- 4564254288&#45;&gt;4799870736 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4564254288-&gt;4799870736</title>\n",
       "<path d=\"M272.5,-365.4551C272.5,-357.3828 272.5,-347.6764 272.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.0001,-338.5903 272.5,-328.5904 269.0001,-338.5904 276.0001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4564383440 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4564383440</title>\n",
       "<polygon fill=\"none\" points=\"121,-219.5 121,-255.5 304,-255.5 304,-219.5 121,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212.5\" y=\"-233.8\">Shared_features: Concatenate</text>\n",
       "</g>\n",
       "<!-- 4543028560&#45;&gt;4564383440 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4543028560-&gt;4564383440</title>\n",
       "<path d=\"M106.3539,-292.4551C125.1655,-282.7157 148.572,-270.5975 168.6148,-260.2207\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"170.2871,-263.2962 177.5583,-255.5904 167.0687,-257.0799 170.2871,-263.2962\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800001424 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>4800001424</title>\n",
       "<polygon fill=\"none\" points=\".5,-73.5 .5,-109.5 176.5,-109.5 176.5,-73.5 .5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.5\" y=\"-87.8\">Concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 4543028560&#45;&gt;4800001424 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>4543028560-&gt;4800001424</title>\n",
       "<path d=\"M61.8947,-292.4191C46.8288,-261.5258 21.2516,-196.9778 40.5,-146 44.5578,-135.2532 51.8071,-125.2528 59.4622,-116.8287\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"62.0674,-119.1701 66.5266,-109.5593 57.0473,-114.2916 62.0674,-119.1701\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4799870736&#45;&gt;4564383440 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4799870736-&gt;4564383440</title>\n",
       "<path d=\"M257.6685,-292.4551C250.4569,-283.6809 241.6583,-272.9759 233.749,-263.353\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"236.4224,-261.0934 227.3688,-255.5904 231.0146,-265.5382 236.4224,-261.0934\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800577680 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>4800577680</title>\n",
       "<polygon fill=\"none\" points=\"227.5,-73.5 227.5,-109.5 403.5,-109.5 403.5,-73.5 227.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-87.8\">Concatenate_2: Concatenate</text>\n",
       "</g>\n",
       "<!-- 4799870736&#45;&gt;4800577680 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>4799870736-&gt;4800577680</title>\n",
       "<path d=\"M291.3856,-292.3577C313.7634,-269.3878 349.7452,-227.4229 363.5,-183 368.3639,-167.2913 369.3089,-161.3843 363.5,-146 359.4422,-135.2532 352.1929,-125.2528 344.5378,-116.8287\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"346.9527,-114.2916 337.4734,-109.5593 341.9326,-119.1701 346.9527,-114.2916\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800054992 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4800054992</title>\n",
       "<polygon fill=\"none\" points=\"50,-146.5 50,-182.5 193,-182.5 193,-146.5 50,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-160.8\">Dense_layer_3: Dense</text>\n",
       "</g>\n",
       "<!-- 4564383440&#45;&gt;4800054992 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4564383440-&gt;4800054992</title>\n",
       "<path d=\"M190.0056,-219.4551C178.5211,-210.2422 164.383,-198.9006 151.9389,-188.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.0414,-186.1177 144.051,-182.5904 149.6612,-191.5779 154.0414,-186.1177\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800453904 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>4800453904</title>\n",
       "<polygon fill=\"none\" points=\"211,-146.5 211,-182.5 354,-182.5 354,-146.5 211,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"282.5\" y=\"-160.8\">Dense_layer_4: Dense</text>\n",
       "</g>\n",
       "<!-- 4564383440&#45;&gt;4800453904 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4564383440-&gt;4800453904</title>\n",
       "<path d=\"M229.8034,-219.4551C238.3011,-210.5932 248.6875,-199.7616 257.986,-190.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"260.7581,-192.2306 265.1531,-182.5904 255.7056,-187.3858 260.7581,-192.2306\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800054992&#45;&gt;4800001424 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>4800054992-&gt;4800001424</title>\n",
       "<path d=\"M113.3427,-146.4551C109.5746,-138.1196 105.0188,-128.0416 100.843,-118.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"103.9864,-117.2608 96.6778,-109.5904 97.6078,-120.1443 103.9864,-117.2608\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800453904&#45;&gt;4800577680 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>4800453904-&gt;4800577680</title>\n",
       "<path d=\"M290.6573,-146.4551C294.4254,-138.1196 298.9812,-128.0416 303.157,-118.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"306.3922,-120.1443 307.3222,-109.5904 300.0136,-117.2608 306.3922,-120.1443\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4564383952 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>4564383952</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-.5 32.5,-36.5 144.5,-36.5 144.5,-.5 32.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.5\" y=\"-14.8\">Output_1: Dense</text>\n",
       "</g>\n",
       "<!-- 4800001424&#45;&gt;4564383952 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>4800001424-&gt;4564383952</title>\n",
       "<path d=\"M88.5,-73.4551C88.5,-65.3828 88.5,-55.6764 88.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"92.0001,-46.5903 88.5,-36.5904 85.0001,-46.5904 92.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4800579472 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>4800579472</title>\n",
       "<polygon fill=\"none\" points=\"259.5,-.5 259.5,-36.5 371.5,-36.5 371.5,-.5 259.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-14.8\">Output_2: Dense</text>\n",
       "</g>\n",
       "<!-- 4800577680&#45;&gt;4800579472 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>4800577680-&gt;4800579472</title>\n",
       "<path d=\"M315.5,-73.4551C315.5,-65.3828 315.5,-55.6764 315.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"319.0001,-46.5903 315.5,-36.5904 312.0001,-46.5904 319.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(x_shaped_net, show_layer_names=True, show_shapes=False).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminar we work with CIFAR-10 dataset.\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetch_cifar import fetch_cifar_dataset\n",
    "X_train, y_train, X_test, y_test, class_names = fetch_cifar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = 10\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('%s' % (class_names[np.where(y_train[k] > 0.0)[0][0]]))\n",
    "        im = ax.imshow(X_train[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convolve!\n",
    "\n",
    "#### Neuro-biologist studying visual perception (Hubel and Wiesel experiments)\n",
    "\n",
    "![Image](https://goodpsychology.files.wordpress.com/2013/03/hubel-experiment.jpg)\n",
    "\n",
    "#### Data scientists studying visual perception (no animal cruelty involved)\n",
    "\n",
    "![Image](http://deeplearning.net/tutorial/_images/mylenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### importing keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.activations import relu\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_cifar_cnn():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    net = inputs\n",
    "    \n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-4\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 4,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 16,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = GlobalMaxPooling2D()(net)\n",
    "    \n",
    "    net = Dense(10, activation='softmax', kernel_regularizer = l2(regularization_coef))(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = make_cifar_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(cnn, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### since the problem is a classification one;\n",
    "### cross-entropy is the most common choice.  \n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "### pretty usual choice of optimizer\n",
    "from keras.optimizers import adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### compile\n",
    "cnn.compile(optimizer=adamax(lr=5.0e-3), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### fit\n",
    "cnn.fit(X_train, y_train, batch_size=32, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = cnn.predict(X_test)\n",
    "print('Accuracy:', np.mean( np.argmax(y_predicted, axis=1) ==  np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-vs-rest ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fprs, tprs = [None] * 10, [None] * 10\n",
    "aucs = [None] * 10\n",
    "\n",
    "for i in range(10):\n",
    "    fprs[i], tprs[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "    aucs[i] = auc(fprs[i], tprs[i], reorder=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "plt.title('One-vs-rest ROC curves', fontsize=16)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(fprs[i], tprs[i], label='%s (AUC %.2lf)' % (class_names[i], aucs[i]))\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_classes = np.argmax(y_predicted, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "c_matrix = confusion_matrix(y_true_classes, y_predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Diagonal excluded\n",
    "c_matrix[np.arange(10), np.arange(10)] = 0.0\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Confusion matrix (diagonal excluded)', fontsize=16)\n",
    "plt.imshow(c_matrix)\n",
    "plt.xticks(np.arange(10), class_names, rotation=45, fontsize=14)\n",
    "plt.yticks(np.arange(10), class_names, fontsize=14)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = 7\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_test.shape[0])\n",
    "        \n",
    "        y_pred = y_predicted[k]\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "        real_class = np.argmax(y_test[k])\n",
    "        score = y_pred[predicted_class]\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        if real_class == predicted_class:\n",
    "            ax.set_title('%s\\nscore: %.3lf' % (class_names[real_class], score))\n",
    "        else:\n",
    "            ax.set_title('real: %s;\\npredicted: %s\\nwith score: %.3lf' % (\n",
    "                class_names[real_class], class_names[predicted_class], score\n",
    "            ))\n",
    "        im = ax.imshow(X_test[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can you do?\n",
    "\n",
    "Here is a several tips on how you can improve the base solution:\n",
    "- add more layers;\n",
    "- add BatchNormalization;\n",
    "- play with activations;\n",
    "- try adjusting regularization;\n",
    "- increase number of filters;\n",
    "- make it fully convolutional (get rid of GlobalMaxPooling by convolving/maxpooling up to 1x1 image, you can use Reshape or Flatten layers to get rid of spatial dimensions);\n",
    "- experiment with the architecture:\n",
    "    - try use conv-conv-pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cheat sheet\n",
    "\n",
    "The standard convolutional networks are built from several types of layers:\n",
    "- [`Convolution`](https://keras.io/layers/convolutional/), ... - performs ... convolution:\n",
    "    - filters: number of filters to use, usually, the number of layers is two timex number of layers in the previous conv. layer; \n",
    "    - kernel_size: size of the convolutional operator, conventional choice is (3, 3);\n",
    "    - padding: padding='same' extends sample with zeros so that sample after convolution has the same width and height, padding='valid' performs convolution only in points where kernel and the sample fully overlap.  \n",
    "    - activation: conventional choice is ReLU or a leaky ReLU.\n",
    "\n",
    "- [`MaxPooling`](https://keras.io/layers/convolutional/) - pools maximal values from pooling area, average pooling is an alternative.\n",
    "\n",
    "- [`GlobalMaxPooling`](https://keras.io/layers/convolutional/) - similar to max pool, but pools from the whole sample/image.\n",
    "\n",
    "- [`Dense`](https://keras.io/layers/core/) - usually is at the end of the network.\n",
    "\n",
    "#### Conv\n",
    "![Image](http://deeplearning.net/tutorial/_images/cnn_explained.png)\n",
    "\n",
    "#### MaxPool\n",
    "\n",
    "![Image](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "\n",
    "#### Conv network\n",
    "\n",
    "![Image](http://deeplearning.net/tutorial/_images/mylenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### importing keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.activations import relu, elu, softplus, tanh, sigmoid\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_super_cnn():\n",
    "    ###\n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-6\n",
    "\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    net = inputs\n",
    "    \n",
    "    ### your network here\n",
    "    \n",
    "    ### previous solution     ###\n",
    "    ### feel free to throw it ###\n",
    "    net = Convolution2D(\n",
    "        filters = 4,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 16,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = GlobalMaxPooling2D()(net)\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    net = Dense(\n",
    "        10, activation='softmax',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_cnn = make_super_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(super_cnn, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### since the problem is a classification one;\n",
    "### cross-entropy is the most common choice.  \n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "### Feel free to play with optimizers\n",
    "### don't forget to adjust learning rate\n",
    "from keras.optimizers import adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### compile\n",
    "super_cnn.compile(optimizer=adamax(lr=5.0e-3), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_cnn.fit(X_train, y_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = cnn.predict(X_test)\n",
    "print('Accuracy:', np.mean( np.argmax(y_predicted, axis=1) ==  np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fprs, tprs = [None] * 10, [None] * 10\n",
    "aucs = [None] * 10\n",
    "\n",
    "for i in range(10):\n",
    "    fprs[i], tprs[i], _ = roc_curve(y_test[:, i], y_predicted[:, i])\n",
    "    aucs[i] = auc(fprs[i], tprs[i], reorder=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "plt.title('One-vs-rest ROC curves')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(fprs[i], tprs[i], label='%s (AUC %.2lf)' % (class_names[i], aucs[i]))\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Diagonal excluded\n",
    "c_matrix[np.arange(10), np.arange(10)] = 0.0\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Confusion matrix (diagonal excluded)', fontsize=16)\n",
    "plt.imshow(c_matrix)\n",
    "plt.xticks(np.arange(10), class_names, rotation=45, fontsize=14)\n",
    "plt.yticks(np.arange(10), class_names, fontsize=14)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = 7\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_test.shape[0])\n",
    "        \n",
    "        y_pred = y_predicted[k]\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "        real_class = np.argmax(y_test[k])\n",
    "        score = y_pred[predicted_class]\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        if real_class == predicted_class:\n",
    "            ax.set_title('%s\\nscore: %.3lf' % (class_names[real_class], score))\n",
    "        else:\n",
    "            ax.set_title('real: %s;\\npredicted: %s\\nwith score: %.3lf' % (\n",
    "                class_names[real_class], class_names[predicted_class], score\n",
    "            ))\n",
    "        im = ax.imshow(X_test[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Deep Jets\n",
    "\n",
    "**WARNING: HARDCORE physics! Details are in the next lecture by Noel Dawe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import h5py\n",
    "\n",
    "DATA_ROOT = '../../../data/deepjets'\n",
    "SIGNAL_PATH = osp.join(DATA_ROOT, 'w_100000_j1p0_sj0p30_delphes_jets_images.h5')\n",
    "BACKGROUND_PATH = osp.join(DATA_ROOT, 'qcd_100000_j1p0_sj0p30_delphes_jets_images.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(filename):\n",
    "    hfile = h5py.File(filename, 'r')\n",
    "    images = hfile['images'].value.astype('float32')\n",
    "\n",
    "    mass = hfile['auxvars']['mass']\n",
    "    pt = hfile['auxvars']['pt']\n",
    "    hfile.close()\n",
    "\n",
    "    # select images in window 50 < mass < 150 GeV and 200 < pt < 300 GeV\n",
    "    #images = images[(mass > 50) & (mass < 150) & (pt > 200) & (pt < 300)]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_signal = get_images(SIGNAL_PATH)\n",
    "X_background = get_images(BACKGROUND_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_background.shape)\n",
    "print(X_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack([X_signal, X_background]).reshape(-1, 25, 25, 1)\n",
    "y = np.hstack([np.ones(X_signal.shape[0], dtype='float32'), np.zeros(X_background.shape[0], dtype='float32')])\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(\n",
    "    [np.mean(X_train[y_train[:, 1] == 1], axis=(1, 2, 3)), np.mean(X_train[y_train[:, 1] == 0], axis=(1, 2, 3))],\n",
    "    bins=100, histtype='step', log=True, label=['W', 'QCD']\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 3 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('%s' % ( \"W\" if y_train[k, 1] == 1 else \"QCD\"))\n",
    "        im = ax.imshow(X_train[k, :, :, 0].T, origin='low', cmap=plt.cm.plasma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### importing keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.activations import relu, elu, softplus, tanh, sigmoid\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_jet_cnn():\n",
    "    ###\n",
    "    leaky_relu = lambda x: relu(x, alpha=5.0e-2)\n",
    "    regularization_coef = 1.0e-6\n",
    "    \n",
    "    ### Note that jets has 1 input channel and different size!\n",
    "    inputs = Input(shape=(25, 25, 1))\n",
    "    normalization = BatchNormalization()(inputs)\n",
    "    \n",
    "    net = normalization\n",
    "    \n",
    "    ### your network here\n",
    "    \n",
    "    ### previous solution     ###\n",
    "    ### feel free to throw it ###\n",
    "    net = Convolution2D(\n",
    "        filters = 32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 128,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((2, 2))(net)\n",
    "    \n",
    "    net = Convolution2D(\n",
    "        filters = 256,\n",
    "        kernel_size=(3, 3),\n",
    "        padding = 'same',\n",
    "        activation=leaky_relu,\n",
    "        kernel_initializer='he_uniform',\n",
    "        kernel_regularizer = l2(regularization_coef)\n",
    "    )(net)\n",
    "    net = MaxPooling2D((3, 3))(net)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    \n",
    "    ### also, 2 classes instead of 10\n",
    "    net = Dense(2, activation='softmax')(net)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jet_net = make_jet_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(jet_net, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jet_net.compile(optimizer=adamax(lr=1.0e-3), loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jet_net.fit(X_train, y_train, batch_size=32, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = jet_net.predict(X_test)\n",
    "print('Accuracy:', np.mean( np.argmax(y_predicted, axis=1) ==  np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test[:, 1], y_predicted[:, 1])\n",
    "auc_score = auc(fpr, tpr, reorder=True)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "\n",
    "plt.title('One-vs-rest ROC curves')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.plot(fpr, tpr, label='W vs QCD (AUC %.3lf)' % (auc_score))\n",
    "\n",
    "plt.legend(fontsize=14, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['QCD', 'W']\n",
    "\n",
    "cols = 7\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        k = np.random.randint(0, X_test.shape[0])\n",
    "        \n",
    "        y_pred = y_predicted[k]\n",
    "        predicted_class = np.argmax(y_pred)\n",
    "        real_class = np.argmax(y_test[k])\n",
    "        score = y_pred[predicted_class]\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        if real_class == predicted_class:\n",
    "            ax.set_title('%s\\nscore: %.3lf' % (class_names[real_class], score))\n",
    "        else:\n",
    "            ax.set_title('real: %s;\\npredicted: %s\\nwith score: %.3lf' % (\n",
    "                class_names[real_class], class_names[predicted_class], score\n",
    "            ))\n",
    "        im = ax.imshow(X_train[k, :, :, 0].T, origin='low', cmap=plt.cm.plasma)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
